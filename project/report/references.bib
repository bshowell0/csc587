% =========================================================================
% BibTeX file for the "On-Device Personalized Agent" project
% =========================================================================

@misc{qwen,
  author = {{Qwen Team}},
  title = {{Qwen3-0.6B}},
  howpublished = {Hugging Face},
  year = {2024},
  note = {[Online]. Available: \url{https://huggingface.co/Qwen/Qwen3-0.6B}}
}

@misc{gosling,
  author = {{Block, Inc.}},
  title = {{Gosling: A framework for building agents on mobile}},
  howpublished = {GitHub Repository},
  year = {2024},
  note = {[Online]. Available: \url{https://github.com/block/gosling}}
}

@article{mobileagentimage,
  author = {Shi, W. and others},
  title = {{Unleashing the Power of Mobile LLMs: A Survey on Frontiers, Applications, and Challenges}},
  journal = {Preprints.org},
  year = {2024},
  note = {[Online]. Available: \url{https://www.preprints.org/manuscript/202401.1278/v1}}
}

@misc{qwen3blog,
  author = {{Qwen Team}},
  title = {{Qwen3 LLM Series: A Big Leap in Performance, Tokenization, and Multilingual Capabilities}},
  howpublished = {QwenLM Blog},
  month = {June},
  year = {2024},
  note = {[Online]. Available: \url{https://qwenlm.github.io/blog/qwen3/}}
}

@article{efficiency,
  author = {Kim, A. and others},
  title = {{MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases}},
  journal = {arXiv preprint arXiv:2312.03863},
  year = {2023}
}

@inproceedings{adapterspaper,
  author = {Houlsby, N. and Giurgiu, A. and Jastrzebski, S. and Morrone, B. and de Laroussilhe, Q. and Gesmundo, A. and Attariyan, M. and Gelly, S.},
  title = {{Parameter-Efficient Transfer Learning for NLP}},
  booktitle = {Proc. Int. Conf. on Machine Learning (ICML)},
  year = {2019}
}

@inproceedings{lora,
  author = {Hu, E. J. and Shen, Y. and Wallis, P. and Allen-Zhu, Z. and Li, Y. and Wang, S. and Wang, L. and Chen, W.},
  title = {{LoRA: Low-Rank Adaptation of Large Language Models}},
  booktitle = {Proc. Int. Conf. on Learning Representations (ICLR)},
  year = {2022}
}

@article{qlora,
  author = {Dettmers, T. and Pagnoni, A. and Holtzman, A. and Zettlemoyer, L.},
  title = {{QLoRA: Efficient Finetuning of Quantized LLMs}},
  journal = {arXiv preprint arXiv:2305.14314},
  year = {2023}
}

@misc{adaptersimage,
  author = {Raschka, S.},
  title = {{Finetuning LLMs with Adapters}},
  howpublished = {Sebastian Raschka's Magazine},
  year = {2023},
  note = {[Online]. Available: \url{https://magazine.sebastianraschka.com/p/finetuning-llms-with-adapters}}
}
